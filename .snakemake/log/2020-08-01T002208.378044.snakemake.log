Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	AdaBoost
	1	Dataexploration
	1	DecisionTree
	1	Random
	1	RandomForest
	1	SVM_CrossVal
	6

[Sat Aug  1 00:22:08 2020]
rule Dataexploration:
    input: input_data_df.csv
    output: output_train_x/flights.csv, output_test_x/flights.csv, output_train_y/flights.csv, output_test_y/flights.csv
    jobid: 5

[Sat Aug  1 00:22:08 2020]
Error in rule Dataexploration:
    jobid: 5
    output: output_train_x/flights.csv, output_test_x/flights.csv, output_train_y/flights.csv, output_test_y/flights.csv
    shell:
        python Dataexploration.py
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/vikasreddy/Desktop/Project/.snakemake/log/2020-08-01T002208.378044.snakemake.log
